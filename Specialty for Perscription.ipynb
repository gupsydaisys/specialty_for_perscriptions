{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import scipy.optimize as opt\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_specialties = ['Internal Medicine', 'Anesthesiology', 'Family Practice', 'Chiropractic',\n",
    "       'Obstetrics/Gynecology', 'Cardiac Surgery',\n",
    "       'Cardiology', 'Dermatology',\n",
    "       'Physical Medicine and Rehabilitation', 'Radiation Oncology',\n",
    "       'Infectious Disease', 'Orthopedic Surgery', 'Endocrinology',\n",
    "       'Urology', 'Emergency Medicine', 'Neurology', 'Nephrology',\n",
    "       'Preventive Medicine', 'Hand Surgery', 'Pulmonary Disease',\n",
    "       'Otolaryngology', 'Plastic and Reconstructive Surgery',\n",
    "       'General Practice', 'Allergy/Immunology', 'Psychiatry',\n",
    "       'Ophthalmology', 'Diagnostic Radiology', 'Psychiatry & Neurology',\n",
    "       'General Surgery', 'Geriatric Medicine',\n",
    "       'Gastroenterology', 'Thoracic Surgery', 'Neuropsychiatry',\n",
    "       'Pain Management', 'Podiatry',\n",
    "       'Hematology/Oncology', 'Optometry', 'Neurosurgery', 'Medical Oncology', 'Surgical Oncology',\n",
    "       'Pediatric Medicine', 'Nuclear Medicine',\n",
    "       'Naturopath', 'Osteopathic Manipulative Medicine',\n",
    "       'Orthopaedic Surgery',\n",
    "       'Family Medicine', 'Rheumatology',\n",
    "       'Vascular Surgery',\n",
    "       'Critical Care (Intensivists)', 'Hospitalist', 'Hematology', 'Maxillofacial Surgery',\n",
    "       'Interventional Pain Management',\n",
    "       'Oral & Maxillofacial Surgery', 'Optician',\n",
    "       'Thoracic Surgery (Cardiothoracic Vascular Surgery)',\n",
    "       'Neurological Surgery', 'Cardiac Electrophysiology',\n",
    "       'Physical Medicine & Rehabilitation', 'Pathology',\n",
    "       'Sports Medicine', 'Sleep Medicine',\n",
    "       'Colorectal Surgery (formerly proctology)', 'Geriatric Psychiatry',\n",
    "       'Addiction Medicine', 'Gynecological/Oncology',\n",
    "       'Interventional Radiology', 'Peripheral Vascular Disease',\n",
    "       'Plastic Surgery',\n",
    "       'Interventional Cardiology', 'Prosthetist',\n",
    "       'Hospice and Palliative Care',\n",
    "       'Neuromusculoskeletal Medicine, Sports Medicine',\n",
    "       'Colon & Rectal Surgery',\n",
    "       'Radiology','Obstetrics & Gynecology',\n",
    "       'Hospital (Dmercs Only)',\n",
    "       'Medical Genetics',\n",
    "       'Clinical Neuropsychologist', 'Naprapath','Pediatrics',\n",
    "       'Audiologist (billing independently)', 'Phlebology']\n",
    "\n",
    "included_set = set(included_specialties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.txt', sep=\"\t\")\n",
    "\n",
    "# Only grab providers who are individuals\n",
    "df = df[df.nppes_provider_first_name.notnull()]\n",
    "\n",
    "# Only grab rows with valid specialties\n",
    "df = df.loc[df.specialty_description.isin(included_set)]\n",
    "\n",
    "# GRAB OLD VALUES\n",
    "#old_X = pd.read_csv('features_combined_total_claim_count.txt', sep=\"\\t\")\n",
    "#old_X_without_column_0 = old_X.drop(old_X.columns[[0]], axis=1)\n",
    "#old_y = pd.read_csv('labels_combined_total_claim_count.txt', sep=\"\\t\")\n",
    "#old_y_without_column_0 = old_y.drop(old_y.columns[[0]], axis=1)\n",
    "\n",
    "# Grab unique npi\n",
    "#int_version_npi = map(int, old_X_without_column_0.npi.unique())\n",
    "#all_npi = df.npi.unique()\n",
    "#set_of_unproccessed_npi = set(all_npi) - set(int_version_npi)\n",
    "#all_unique_npi = np.asarray(list(set_of_unproccessed_npi))\n",
    "#all_unique_npi = df.npi.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO LOAD THIS FROM FILE\n",
    "all_specialties = df.specialty_description.unique()\n",
    "index_for_specialty = dict((specialty,i) for i, specialty in enumerate(all_specialties))\n",
    "inv_map = {v: k for k, v in index_for_specialty.iteritems()}\n",
    "temp = pd.DataFrame(all_specialties)\n",
    "temp.to_csv(\"all_specialties_bene_count_50_000.txt\", sep='\\t')\n",
    "\n",
    "# TODO LOAD THIS FROM FILE\n",
    "all_generic_names = df.generic_name.unique()\n",
    "X_header = np.insert(all_generic_names, 0, 'npi')\n",
    "temp = pd.DataFrame(X_header)\n",
    "temp.to_csv(\"header_bene_count_50_000.txt\", sep='\\t')\n",
    "feature_size = X_header.shape[0]\n",
    "generic_name_to_index = {}\n",
    "for i, generic_name in enumerate(X_header):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    generic_name_to_index[generic_name] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.npi.unique().shape  ==== >> (807973,)\n",
    "#s0 = all_unique_npi[0:10000]\n",
    "#s1 = all_unique_npi[100000:200000]\n",
    "#s2 = all_unique_npi[200000:300000]\n",
    "#s3 = all_unique_npi[300000:400000]\n",
    "#s4 = all_unique_npi[400000:500000]\n",
    "#s5 = all_unique_npi[500000:600000]\n",
    "#s6 = all_unique_npi[600000:700000]\n",
    "#s7 = all_unique_npi[700000:900000]\n",
    "# DOES NOT ERROR USING A INDEX > THAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = pd.DataFrame(columns=X_header)\n",
    "#y = np.zeros(s0.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n"
     ]
    }
   ],
   "source": [
    "s0 = all_unique_npi[0:50000]\n",
    "X = pd.DataFrame(columns=X_header)\n",
    "y = np.zeros(s0.shape[0])\n",
    "for i, npi in enumerate(s0):\n",
    "    if (i % 500) == 0:\n",
    "        print i\n",
    "    npi_matches = df.loc[df['npi'] == npi]\n",
    "\n",
    "    speciality = npi_matches.specialty_description.values[0]\n",
    "    y[i] = index_for_specialty[speciality]\n",
    "\n",
    "    # We need to normalize bene_count across doctor's panel otherwise might be getting strange numbers\n",
    "    total_bene_counts = npi_matches.bene_count.fillna(5).sum()\n",
    "    feature_vector = np.zeros(feature_size)\n",
    "    feature_vector[0] = npi\n",
    "    for generic_name in npi_matches.generic_name.unique():\n",
    "        generic_name_matches = npi_matches.loc[npi_matches['generic_name'] == generic_name]\n",
    "        index_for_feature_vector = generic_name_to_index[generic_name]\n",
    "        normalized_bene_count = generic_name_matches.bene_count.fillna(5).sum() / total_bene_counts\n",
    "        feature_vector[index_for_feature_vector] = normalized_bene_count\n",
    "    X.loc[i] = feature_vector\n",
    "    \n",
    "# https://stackoverflow.com/questions/16923281/pandas-writing-dataframe-to-csv-file\n",
    "X.to_csv(\"features_bene_count_50_000.txt\", sep='\\t')\n",
    "pd.DataFrame(y).to_csv(\"labels_bene_count_50_000.txt\", sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1\n",
      "1788 8000\n"
     ]
    }
   ],
   "source": [
    "# X0 = old_X_without_column_0\n",
    "# y0 = old_y_without_column_0\n",
    "\n",
    "# Xtrain= X0.head(32000)\n",
    "# Xtest = X0.tail(8000)\n",
    "\n",
    "# Y = pd.DataFrame(y0)\n",
    "# Ytrain = Y.head(32000)\n",
    "# Ytest = Y.tail(8000)\n",
    "\n",
    "# Xtrain_without_npi = Xtrain.drop(columns=['npi'])\n",
    "# Xtest_without_npi = Xtest.drop(columns=['npi'])\n",
    "\n",
    "# clf = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "# model = clf.fit(Xtrain_without_npi, Ytrain.values.ravel())\n",
    "    \n",
    "# print len(set(Ytrain)), len(set(Ytest)), len(set(Ytrain).intersection(set(Ytest)))\n",
    "\n",
    "# Ytest_predict_proba0 = model.predict_proba(Xtest_without_npi)\n",
    "\n",
    "# Ytest_predict0 = model.predict(Xtest_without_npi)\n",
    "\n",
    "# yravel = Ytest.values.ravel()\n",
    "# total_abs = len(yravel)\n",
    "# total_good = 0\n",
    "# for i, e in enumerate(Ytest_predict0):\n",
    "#     if e == yravel[i]:\n",
    "#         total_good = total_good + 1\n",
    "    \n",
    "# print total_good, total_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain= X.head(32000)\n",
    "Xtest = X.tail(8000)\n",
    "\n",
    "Y = pd.DataFrame(y)\n",
    "Ytrain = Y.head(32000)\n",
    "Ytest = Y.tail(8000)\n",
    "\n",
    "#print Y.shape, Ytrain.shape, Ytest.shape\n",
    "Xtrain_without_npi = Xtrain.drop(columns=['npi'])\n",
    "Xtest_without_npi = Xtest.drop(columns=['npi'])\n",
    "\n",
    "#Xtrain = old_X_without_column_0.head(4900)\n",
    "#Xtest = old_X_without_column_0.head(100)\n",
    "\n",
    "#Y = old_y_without_column_0\n",
    "#Ytrain = old_y_without_column_0.head(4900)\n",
    "#Ytest = old_y_without_column_0.head(100)\n",
    "\n",
    "#Xtrain_without_npi = Xtrain.drop(columns=['npi'])\n",
    "#Xtest_without_npi = Xtest.drop(columns=['npi'])\n",
    "#combined_X.shape, y.shape, old_y_without_column_0.shape\n",
    "#old_y_without_column_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "clf = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "model = clf.fit(Xtrain_without_npi, Ytrain.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 73, 71, 70)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_values = set()\n",
    "for e in pd.DataFrame(Ytrain).values:\n",
    "    ytrain_values.add(inv_map[e[0]])\n",
    "    \n",
    "ytest_values = set()\n",
    "for e in pd.DataFrame(Ytest).values:\n",
    "    ytest_values.add(inv_map[e[0]])\n",
    "    \n",
    "len(included_specialties), len(ytrain_values), len(ytest_values), len(ytrain_values.intersection(ytest_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest_predict_proba = model.predict_proba(Xtest_without_npi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest_predict = model.predict(Xtest_without_npi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4856 8000\n"
     ]
    }
   ],
   "source": [
    "yravel = Ytest.values.ravel()\n",
    "total_abs = len(yravel)\n",
    "total_good = 0\n",
    "good = set()\n",
    "bad = set()\n",
    "for i, e in enumerate(Ytest_predict):\n",
    "    if e == yravel[i]:\n",
    "        total_good = total_good + 1\n",
    "        good.add(inv_map[e])\n",
    "    bad.add((inv_map[e], inv_map[yravel[i]]))\n",
    "    \n",
    "print total_good, total_abs\n",
    "#print good\n",
    "#print bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xtrain0 = X.head(4500)\n",
    "#Xtrain1 = X.tail(5500).head(4500)\n",
    "#Xtest = X.tail(5500).tail(1000)\n",
    "\n",
    "#Y = pd.DataFrame(y)\n",
    "#Ytrain0 = Y.head(4500)\n",
    "#Ytrain1 = Y.tail(5500).head(4500)\n",
    "#Ytest = Y.tail(5500).tail(1000)\n",
    "\n",
    "#Xtrain0_without_npi = Xtrain0.drop(columns=['npi'])\n",
    "#Xtrain1_without_npi = Xtrain1.drop(columns=['npi'])\n",
    "#Xtest_without_npi = Xtest.drop(columns=['npi'])\n",
    "\n",
    "#clf_without_extra_features = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "#model = clf_without_extra_features.fit(Xtrain0_without_npi, Ytrain0.values.ravel())\n",
    "\n",
    "#Ytrain1_predict_proba = model.predict_proba(Xtrain1_without_npi)\n",
    "\n",
    "#Xtrain1_without_npi.shape, pd.DataFrame(Ytrain1_predict_proba).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In [3]:\n",
    "#\n",
    "#df1 = pd.DataFrame([1,2,3], index = np.arange(2000))\n",
    "#df2 = pd.DataFrame([3,5,3], index = np.arange(2000))\n",
    "#pd.concat([df1,df2], axis=1)\n",
    "#Out[3]:\n",
    "#   0  0\n",
    "#2  1  3\n",
    "#3  2  5\n",
    "#4  3  3\n",
    "\n",
    "#size = len(Ytest_predict_proba)\n",
    "#df1 = pd.DataFrame(Ytest_predict_proba, index = np.arange(size))\n",
    "#df2 = pd.DataFrame(Xtest_without_npi, index = np.arange(size))\n",
    "#meow = pd.concat([df1,pd.DataFrame(df2)], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
